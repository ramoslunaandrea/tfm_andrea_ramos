{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac97536-619e-4e25-85d6-11a823a34424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND VERSION CHECK\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "from time import strftime\n",
    "import requests\n",
    "\n",
    "# PyDESeq2\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "\n",
    "# Config reproducible\n",
    "np.random.seed(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a069856-b21f-4915-adc9-929e338d6f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: c:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\n",
      "Input dir: data\n",
      "Output dir: results\n"
     ]
    }
   ],
   "source": [
    "# ENV AND PATHS\n",
    "\n",
    "# Load environment variables from .env file\n",
    "repo_root = Path.cwd().parent\n",
    "load_dotenv(repo_root / \".env\")\n",
    "\n",
    "# Paths\n",
    "INPUT_DIR = Path(os.getenv(\"INPUT_DIR\"))\n",
    "OUTPUT_DIR = Path(os.getenv(\"OUTPUT_DIR\"))\n",
    "\n",
    "# Inputs\n",
    "RAW_DIR = (repo_root / INPUT_DIR / \"raw\" / \"functional_annotation\").resolve()\n",
    "META_PATH = (repo_root / INPUT_DIR / \"metadata\" / \"metadata.csv\").resolve()\n",
    "\n",
    "# Outputs\n",
    "analysis_name = \"01_deseq_study\"\n",
    "OUT_ROOT = (repo_root / OUTPUT_DIR / analysis_name).resolve()\n",
    "OUT_CSV = OUT_ROOT / \"csv\"\n",
    "OUT_PLOTS = OUT_ROOT / \"plots\"\n",
    "for d in [OUT_ROOT, OUT_CSV, OUT_PLOTS]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#Check paths\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Input dir: {INPUT_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aba8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "def read_emapper(raw_dir, pattern=\"ERR*.emapper.annotations\"):\n",
    "    \"\"\"\n",
    "    Read all *.emapper.annotations files under `raw_dir` matching `pattern`\n",
    "    and return a single long DataFrame with columns:\n",
    "        ['sample_id', 'query', 'KEGG_Module'].\n",
    "    \"\"\"\n",
    "    raw_dir = Path(raw_dir)\n",
    "    files = sorted(raw_dir.glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files matching '{pattern}' found in {raw_dir}\")\n",
    "\n",
    "    all_dfs = []\n",
    "    for fp in files:\n",
    "        m = re.search(r\"(ERR\\d+)\", fp.name, flags=re.I)\n",
    "        sample_id = m.group(1).upper() if m else fp.stem.split(\".\")[0]\n",
    "\n",
    "        header = None\n",
    "        with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"#query\"):\n",
    "                    header = line.lstrip(\"#\").strip().split(\"\\t\")\n",
    "                    break\n",
    "        if header is None:\n",
    "            print(f\"Skipping {fp.name}: no '#query' header found.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(fp, sep=\"\\t\", comment=\"#\", names=header, dtype=str, low_memory=False)\n",
    "        df = df[[\"query\", \"KEGG_Module\"]].dropna()\n",
    "        df = df[df[\"KEGG_Module\"] != \"-\"]\n",
    "        df[\"KEGG_Module\"] = df[\"KEGG_Module\"].astype(str).str.split(\",\")\n",
    "        df = df.explode(\"KEGG_Module\", ignore_index=True)\n",
    "        df[\"KEGG_Module\"] = df[\"KEGG_Module\"].str.strip()\n",
    "        df = df[df[\"KEGG_Module\"] != \"\"]\n",
    "\n",
    "        df.insert(0, \"sample_id\", sample_id)\n",
    "        all_dfs.append(df[[\"sample_id\", \"query\", \"KEGG_Module\"]])\n",
    "\n",
    "    if not all_dfs:\n",
    "        raise RuntimeError(\"No valid annotation files could be read.\")\n",
    "\n",
    "    out = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"Loaded {len(files)} files — {out['sample_id'].nunique()} samples, {len(out):,} rows.\")\n",
    "    return out\n",
    "\n",
    "def summarize_modules(df):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "      - long_counts: ['sample_id','KEGG_Module','n_proteins'] (#unique queries per module)\n",
    "      - matrix: samples x modules (counts)\n",
    "    \"\"\"\n",
    "    long_counts = (\n",
    "        df.groupby([\"sample_id\", \"KEGG_Module\"])[\"query\"]\n",
    "        .nunique()\n",
    "        .reset_index(name=\"n_proteins\")\n",
    "    )\n",
    "    matrix = (\n",
    "        long_counts\n",
    "        .pivot(index=\"sample_id\", columns=\"KEGG_Module\", values=\"n_proteins\")\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    return long_counts, matrix\n",
    "\n",
    "def fetch_kegg_reference():\n",
    "    \"\"\"\n",
    "    Fetch KEGG module reference (KEGG_Module, Module_name, Module_description).\n",
    "    \"\"\"\n",
    "    url = \"https://rest.kegg.jp/list/module\"\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    lines = [line.split(\"\\t\") for line in r.text.strip().split(\"\\n\")]\n",
    "    df = pd.DataFrame(lines, columns=[\"KEGG_Module\", \"Description\"])\n",
    "    df[\"KEGG_Module\"] = df[\"KEGG_Module\"].str.replace(\"module:\", \"\", regex=False).str.strip()\n",
    "    df[\"Module_name\"] = df[\"Description\"].str.split(\",\", n=1).str[0]\n",
    "    df[\"Module_description\"] = df[\"Description\"]\n",
    "    return df.drop_duplicates(subset=[\"KEGG_Module\"])\n",
    "\n",
    "def percent_unmapped(modules, reference_df):\n",
    "    \"\"\"\n",
    "    Percentage of modules in `modules` that are NOT present in the KEGG reference dataframe.\n",
    "    \"\"\"\n",
    "    present = set(modules)\n",
    "    found = set(reference_df[\"KEGG_Module\"])\n",
    "    missing = [m for m in present if m not in found]\n",
    "    return round(100 * len(missing) / len(present), 2) if present else 0.0\n",
    "\n",
    "def matrix_sparsity(matrix):\n",
    "    \"\"\"\n",
    "    Sparsity (percentage of zeros) in a counts matrix.\n",
    "    \"\"\"\n",
    "    total = matrix.size\n",
    "    zeros = (matrix == 0).sum().sum()\n",
    "    return round(100 * zeros / total, 2) if total else 0.0\n",
    "\n",
    "# Read metadata\n",
    "\n",
    "def load_metadata(meta_path):\n",
    "    \"\"\"\n",
    "    Load metadata.csv and return DataFrame with columns: ['sample_id', 'group'].\n",
    "    Expects columns 'NCBI_accession' and 'study_condition'.\n",
    "    \"\"\"\n",
    "    meta = pd.read_csv(meta_path)\n",
    "    if \"NCBI_accession\" not in meta.columns or \"study_condition\" not in meta.columns:\n",
    "        raise ValueError(\"Metadata must have columns 'NCBI_accession' and 'study_condition'.\")\n",
    "    meta[\"sample_id\"] = (\n",
    "        meta[\"NCBI_accession\"].astype(str).str.extract(r\"(ERR\\d+)\", expand=False).str.upper()\n",
    "    )\n",
    "    meta[\"group\"] = meta[\"study_condition\"].astype(str).str.strip().str.lower()\n",
    "    meta = meta.dropna(subset=[\"sample_id\", \"group\"]).drop_duplicates(\"sample_id\")\n",
    "    return meta[[\"sample_id\", \"group\"]]\n",
    "\n",
    "# Results \n",
    "\n",
    "def save_csv(df, out_dir, name):\n",
    "    \"\"\"\n",
    "    Save a DataFrame as CSV inside `out_dir`.\n",
    "    Automatically adds a timestamp unless stamp=False.\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = out_dir / f\"{name}.csv\"\n",
    "    df.to_csv(file_path, index=True)\n",
    "    print(f\"CSV saved in: {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "def save_plot(out_dir, name, dpi=300):\n",
    "    \"\"\"\n",
    "    Save the current Matplotlib figure in `out_dir` with timestamp.\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = out_dir / f\"{name}.png\"\n",
    "    plt.savefig(file_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"FIG saved in: {file_path}\")\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ff66e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 171 files — 171 samples, 9,237,561 rows.\n",
      "Total KEGG_Module annotations: 9,237,561\n",
      "Matrix shape (samples x modules): (171, 757) | Sparsity: 30.07%\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\annotations_long.csv\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\counts_long.csv\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\counts_matrix.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Andre/OneDrive/Escritorio/tfm_andrea_ramos/results/01_deseq_study/csv/counts_matrix.csv')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD ANNOTATIONS AND BUILD ABUNDANCE MATRIX (E-MAPPER -> LONG AND MATRIX)\n",
    "\n",
    "# Read all emapper annotations\n",
    "annotations_long = read_emapper(RAW_DIR) \n",
    "print(f\"Total KEGG_Module annotations: {len(annotations_long):,}\")\n",
    "\n",
    "# Summarize to long_counts and counts matrix (samples x modules)\n",
    "long_counts, matrix = summarize_modules(annotations_long)\n",
    "print(f\"Matrix shape (samples x modules): {matrix.shape} | Sparsity: {matrix_sparsity(matrix)}%\")\n",
    "\n",
    "# Save CSV outputs\n",
    "save_csv(annotations_long, OUT_CSV, \"annotations_long\")\n",
    "save_csv(long_counts, OUT_CSV, \"counts_long\")\n",
    "save_csv(matrix, OUT_CSV, \"counts_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "228437d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_csv(OUT_CSV / \"counts_matrix.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9619c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of matrix modules not found in KEGG: 55.88%\n",
      "Modules retained with KEGG description: 334\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\kegg_reference.csv\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\counts_long_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "# KEGG MODULE ANNOTATION AND FILTER \n",
    "\n",
    "try:\n",
    "    kmap = fetch_kegg_reference()\n",
    "    pct_unmapped = percent_unmapped(matrix.columns, kmap)\n",
    "    print(f\"% of matrix modules not found in KEGG: {pct_unmapped}%\")\n",
    "\n",
    "    # Annotate long table and keep only modules that exist in KEGG\n",
    "    long_counts_annot = long_counts.merge(kmap, on=\"KEGG_Module\", how=\"inner\")\n",
    "    valid_mods = set(long_counts_annot[\"KEGG_Module\"].unique())\n",
    "    matrix = matrix.loc[:, sorted([c for c in matrix.columns if c in valid_mods])]\n",
    "    print(f\"Modules retained with KEGG description: {matrix.shape[1]}\")\n",
    "\n",
    "    # Save\n",
    "    save_csv(kmap, OUT_CSV, \"kegg_reference\")\n",
    "    save_csv(long_counts_annot, OUT_CSV, \"counts_long_annotated\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"KEGG fetch failed; continuing without annotation:\", e)\n",
    "    kmap = None\n",
    "    long_counts_annot = long_counts.copy()\n",
    "    long_counts_annot[\"Module_name\"] = long_counts_annot[\"KEGG_Module\"]\n",
    "    long_counts_annot[\"Module_description\"] = \"NA\"\n",
    "    \n",
    "    # Save fallback\n",
    "    save_csv(long_counts_annot, OUT_CSV, \"counts_long_annotated_fallback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "271a8518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\counts_unfiltered.csv\n",
      "Unfiltered counts saved: (171, 334)\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\counts_filtered.csv\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\metadata_aligned.csv\n",
      "DESeq2 inputs:\n",
      "  counts_unfiltered: (171, 334)\n",
      "  counts_filtered:   (171, 305)\n",
      "  metadata:          (171, 1)\n",
      "Groups: {'schizophrenia': 90, 'control': 81}\n"
     ]
    }
   ],
   "source": [
    "# METADATA AND MERGE\n",
    "\n",
    "# Load metadata\n",
    "meta = load_metadata(META_PATH)\n",
    "TARGET_GROUPS = [\"control\", \"schizophrenia\"]\n",
    "meta = meta[meta[\"group\"].isin([g.lower() for g in TARGET_GROUPS])].copy()\n",
    "\n",
    "# Set index to sample_id\n",
    "meta = meta.set_index(\"sample_id\").sort_index()\n",
    "matrix = matrix.sort_index()\n",
    "\n",
    "# Inner join\n",
    "joined = matrix.join(meta, how=\"inner\")\n",
    "\n",
    "if joined.empty:\n",
    "    raise RuntimeError(\"Inner join produced an empty set: no overlapping samples between counts and metadata.\")\n",
    "\n",
    "# Split back into DESeq2 objects (counts_df and metadata)\n",
    "metadata = joined[[\"group\"]].copy()\n",
    "counts_df = joined.drop(columns=[\"group\"]).astype(int)\n",
    "\n",
    "# Save unfiltered count matrix\n",
    "save_csv(counts_df, OUT_CSV, \"counts_unfiltered\")\n",
    "print(f\"Unfiltered counts saved: {counts_df.shape}\")\n",
    "\n",
    "# Filter low-abundance modules\n",
    "counts_filtered = counts_df.loc[:, (counts_df.sum(axis=0) >= 10)]\n",
    "\n",
    "# Save the filtered count matrix\n",
    "save_csv(counts_filtered, OUT_CSV, \"counts_filtered\")\n",
    "save_csv(metadata, OUT_CSV, \"metadata_aligned\")\n",
    "\n",
    "# Report summary\n",
    "print(\"DESeq2 inputs:\")\n",
    "print(\"  counts_unfiltered:\", counts_df.shape)\n",
    "print(\"  counts_filtered:  \", counts_filtered.shape)\n",
    "print(\"  metadata:         \", metadata.shape)\n",
    "print(\"Groups:\", metadata[\"group\"].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "810c1c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\counts_matrix_with_metadata.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Andre/OneDrive/Escritorio/tfm_andrea_ramos/results/01_deseq_study/csv/counts_matrix_with_metadata.csv')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNT MATRIX + METADATA\n",
    "# Combine original counts_matrix (samples x modules) with metadata and save\n",
    "counts_matrix_with_meta = metadata.join(matrix, how=\"inner\")\n",
    "save_csv(counts_matrix_with_meta, OUT_CSV, \"counts_matrix_with_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7480bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting size factors...\n",
      "... done in 0.02 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using None as control genes, passed at DeseqDataSet initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting dispersions...\n",
      "... done in 0.34 seconds.\n",
      "\n",
      "Fitting dispersion trend curve...\n",
      "c:\\Users\\Andre\\miniconda3\\envs\\tfm\\Lib\\site-packages\\pydeseq2\\dds.py:807: UserWarning: The dispersion trend curve fitting did not converge. Switching to a mean-based dispersion trend.\n",
      "  self._fit_parametric_dispersion_trend(vst)\n",
      "... done in 0.06 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 0.48 seconds.\n",
      "\n",
      "Fitting LFCs...\n",
      "... done in 0.26 seconds.\n",
      "\n",
      "Calculating cook's distance...\n",
      "... done in 0.02 seconds.\n",
      "\n",
      "Replacing 0 outlier genes.\n",
      "\n",
      "Running Wald tests...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2 fold change & Wald test p-value: group schizophrenia vs control\n",
      "          baseMean  log2FoldChange     lfcSE      stat    pvalue      padj\n",
      "M00001  755.155210        0.008188  0.009872  0.829474  0.406836  0.892698\n",
      "M00002  405.801700        0.004106  0.014211  0.288897  0.772660  0.999723\n",
      "M00003  525.165444        0.014409  0.010788  1.335679  0.181654  0.688905\n",
      "M00004  451.492611        0.006004  0.010786  0.556618  0.577789  0.999723\n",
      "M00005   66.487499        0.020617  0.026422  0.780303  0.435213  0.909177\n",
      "...            ...             ...       ...       ...       ...       ...\n",
      "M00841  186.060300       -0.021877  0.016232 -1.347745  0.177740  0.688905\n",
      "M00842   67.482778       -0.024876  0.026574 -0.936131  0.349206  0.875098\n",
      "M00843   67.491975       -0.024243  0.026568 -0.912475  0.361519  0.875098\n",
      "M00844  162.463244        0.009870  0.017051  0.578824  0.562708  0.999723\n",
      "M00845  264.751661       -0.004839  0.013454 -0.359665  0.719098  0.999723\n",
      "\n",
      "[305 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... done in 0.25 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DIFFERENTIAL ANALYSIS (PyDESeq2)\n",
    "\n",
    "# Configure groups and set reference\n",
    "metadata = metadata.copy()\n",
    "metadata[\"group\"] = pd.Categorical(\n",
    "    metadata[\"group\"].str.lower(),\n",
    "    categories=[\"control\", \"schizophrenia\"],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Initialize DESeqDataSet\n",
    "dds = DeseqDataSet(\n",
    "    counts=counts_filtered,\n",
    "    metadata=metadata,      \n",
    "    design=\"~ group\",\n",
    "    refit_cooks=True\n",
    ")\n",
    "dds.deseq2()\n",
    "\n",
    "# Contrast: schizophrenia vs control\n",
    "ds = DeseqStats(\n",
    "    dds, \n",
    "    contrast=[\"group\", \"schizophrenia\", \"control\"],\n",
    "    alpha=0.05,\n",
    "    cooks_filter=True,\n",
    "    independent_filter=True\n",
    ")\n",
    "ds.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fbb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tested modules: 305\n",
      "Significant (padj < 0.05): 5 | Up: 2 | Down: 3\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\significant_modules__schizophrenia_vs_control.csv\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\significant_modules_annotated__schizophrenia_vs_control.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Andre/OneDrive/Escritorio/tfm_andrea_ramos/results/01_deseq_study/csv/significant_modules_annotated__schizophrenia_vs_control.csv')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET RESULTS AND SIGNIFICANT MODULES\n",
    "res_df = ds.results_df.copy()\n",
    "res_df = res_df.reset_index()\n",
    "if \"KEGG_Module\" not in res_df.columns:\n",
    "    # First column after reset_index() is the module IDs\n",
    "    res_df = res_df.rename(columns={res_df.columns[0]: \"KEGG_Module\"})\n",
    "\n",
    "res_clean = res_df.dropna(subset=[\"log2FoldChange\", \"padj\"]).copy()\n",
    "\n",
    "# Significant list (padj < 0.05)\n",
    "sig = res_clean[res_clean[\"padj\"] < 0.05].sort_values(\"padj\", na_position=\"last\").copy()\n",
    "n_total = res_clean.shape[0]\n",
    "n_sig   = sig.shape[0]\n",
    "n_up    = int((sig[\"log2FoldChange\"] > 0).sum())\n",
    "n_down  = int((sig[\"log2FoldChange\"] < 0).sum())\n",
    "\n",
    "print(f\"Total tested modules: {n_total}\")\n",
    "print(f\"Significant (padj < 0.05): {n_sig} | Up: {n_up} | Down: {n_down}\")\n",
    "\n",
    "# Save significant table\n",
    "case_group = \"schizophrenia\"\n",
    "ref_group  = \"control\"\n",
    "save_csv(sig, OUT_CSV, f\"significant_modules__{case_group}_vs_{ref_group}\")\n",
    "\n",
    "# Save significant results with annotation\n",
    "if \"kmap\" in globals() and isinstance(kmap, pd.DataFrame) and not kmap.empty:\n",
    "    sig_annot = sig.merge(kmap, on=\"KEGG_Module\", how=\"left\")\n",
    "else:\n",
    "    print(\"KEGG reference not available, skipping annotation.\")\n",
    "    sig_annot = sig.copy()\n",
    "    sig_annot[\"Module_name\"] = sig_annot[\"KEGG_Module\"]\n",
    "    sig_annot[\"Module_description\"] = \"NA\"\n",
    "\n",
    "# Add direction column (up/down regulation)\n",
    "sig_annot[\"direction\"] = np.where(\n",
    "    sig_annot[\"log2FoldChange\"] > 0, \"up_in_schizophrenia\", \"down_in_schizophrenia\"\n",
    ")\n",
    "\n",
    "# Save annotated table\n",
    "save_csv(sig_annot, OUT_CSV, f\"significant_modules_annotated__{case_group}_vs_{ref_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c5816d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIG saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\plots\\hist_log2fc_mean_pm_sd__schizophrenia_vs_control.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Andre/OneDrive/Escritorio/tfm_andrea_ramos/results/01_deseq_study/plots/hist_log2fc_mean_pm_sd__schizophrenia_vs_control.png')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LFC distribution: seaborn histogram with KDE and mean ± SD lines\n",
    "lfc = res_clean[\"log2FoldChange\"].astype(float)\n",
    "mu  = float(lfc.mean())\n",
    "sd  = float(lfc.std(ddof=1))\n",
    "\n",
    "plt.figure()\n",
    "sns.histplot(lfc, bins=50, kde=True)\n",
    "plt.axvline(mu,             ls=\"-\",  lw=2,   color=\"black\", label=f\"Mean = {mu:.2f}\")\n",
    "plt.axvline(mu - sd,        ls=\"--\", lw=1.5, color=\"gray\",  label=f\"Mean ± SD ({sd:.2f})\")\n",
    "plt.axvline(mu + sd,        ls=\"--\", lw=1.5, color=\"gray\")\n",
    "plt.xlabel(\"log2 Fold Change\")\n",
    "plt.title(f\"LFC distribution ({case_group} vs {ref_group}) with Mean ± SD\")\n",
    "plt.legend()\n",
    "save_plot(OUT_PLOTS, f\"hist_log2fc_mean_pm_sd__{case_group}_vs_{ref_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802ee72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
