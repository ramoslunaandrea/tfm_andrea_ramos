{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fac97536-619e-4e25-85d6-11a823a34424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND VERSION CHECK\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "# PyDESeq2\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "\n",
    "# Config reproducible\n",
    "np.random.seed(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a069856-b21f-4915-adc9-929e338d6f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: c:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\n",
      "Input dir: data\n",
      "Output dir: results\n"
     ]
    }
   ],
   "source": [
    "# ENV AND PATHS\n",
    "\n",
    "# Load environment variables from .env file\n",
    "repo_root = Path.cwd().parent\n",
    "load_dotenv(repo_root / \".env\")\n",
    "\n",
    "# Paths\n",
    "INPUT_DIR = Path(os.getenv(\"INPUT_DIR\"))\n",
    "OUTPUT_DIR = Path(os.getenv(\"OUTPUT_DIR\"))\n",
    "\n",
    "# Inputs\n",
    "RAW_DIR = (repo_root / INPUT_DIR / \"raw\" / \"functional_annotation\").resolve()\n",
    "META_PATH = (repo_root / INPUT_DIR / \"metadata\" / \"metadata.csv\").resolve()\n",
    "\n",
    "# Outputs\n",
    "analysis_name = \"01_deseq_study\"\n",
    "OUT_ROOT = (repo_root / OUTPUT_DIR / analysis_name).resolve()\n",
    "OUT_CSV = OUT_ROOT / \"csv\"\n",
    "OUT_PLOTS = OUT_ROOT / \"plots\"\n",
    "for d in [OUT_ROOT, OUT_CSV, OUT_PLOTS]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#Check paths\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Input dir: {INPUT_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aba8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "def read_emapper(raw_dir, pattern=\"ERR*.emapper.annotations\"):\n",
    "    \"\"\"\n",
    "    Read all *.emapper.annotations files under `raw_dir` matching `pattern`\n",
    "    and return a single long DataFrame with columns:\n",
    "        ['sample_id', 'query', 'KEGG_Module'].\n",
    "    \"\"\"\n",
    "    raw_dir = Path(raw_dir)\n",
    "    files = sorted(raw_dir.glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files matching '{pattern}' found in {raw_dir}\")\n",
    "\n",
    "    all_dfs = []\n",
    "    for fp in files:\n",
    "        m = re.search(r\"(ERR\\d+)\", fp.name, flags=re.I)\n",
    "        sample_id = m.group(1).upper() if m else fp.stem.split(\".\")[0]\n",
    "\n",
    "        header = None\n",
    "        with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"#query\"):\n",
    "                    header = line.lstrip(\"#\").strip().split(\"\\t\")\n",
    "                    break\n",
    "        if header is None:\n",
    "            print(f\"Skipping {fp.name}: no '#query' header found.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(fp, sep=\"\\t\", comment=\"#\", names=header, dtype=str, low_memory=False)\n",
    "        df = df[[\"query\", \"KEGG_Module\"]].dropna()\n",
    "        df = df[df[\"KEGG_Module\"] != \"-\"]\n",
    "        df[\"KEGG_Module\"] = df[\"KEGG_Module\"].astype(str).str.split(\",\")\n",
    "        df = df.explode(\"KEGG_Module\", ignore_index=True)\n",
    "        df[\"KEGG_Module\"] = df[\"KEGG_Module\"].str.strip()\n",
    "        df = df[df[\"KEGG_Module\"] != \"\"]\n",
    "\n",
    "        df.insert(0, \"sample_id\", sample_id)\n",
    "        all_dfs.append(df[[\"sample_id\", \"query\", \"KEGG_Module\"]])\n",
    "\n",
    "    if not all_dfs:\n",
    "        raise RuntimeError(\"No valid annotation files could be read.\")\n",
    "\n",
    "    out = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"Loaded {len(files)} files — {out['sample_id'].nunique()} samples, {len(out):,} rows.\")\n",
    "    return out\n",
    "\n",
    "def summarize_modules(df):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "      - long_counts: ['sample_id','KEGG_Module','n_proteins'] (#unique queries per module)\n",
    "      - matrix: samples x modules (counts)\n",
    "    \"\"\"\n",
    "    long_counts = (\n",
    "        df.groupby([\"sample_id\", \"KEGG_Module\"])[\"query\"]\n",
    "        .nunique()\n",
    "        .reset_index(name=\"n_proteins\")\n",
    "    )\n",
    "    matrix = (\n",
    "        long_counts\n",
    "        .pivot(index=\"sample_id\", columns=\"KEGG_Module\", values=\"n_proteins\")\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    return long_counts, matrix\n",
    "\n",
    "def fetch_kegg_reference():\n",
    "    \"\"\"\n",
    "    Fetch KEGG module reference (KEGG_Module, Module_name, Module_description).\n",
    "    \"\"\"\n",
    "    url = \"https://rest.kegg.jp/list/module\"\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    lines = [line.split(\"\\t\") for line in r.text.strip().split(\"\\n\")]\n",
    "    df = pd.DataFrame(lines, columns=[\"KEGG_Module\", \"Description\"])\n",
    "    df[\"KEGG_Module\"] = df[\"KEGG_Module\"].str.replace(\"module:\", \"\", regex=False).str.strip()\n",
    "    df[\"Module_name\"] = df[\"Description\"].str.split(\",\", n=1).str[0]\n",
    "    df[\"Module_description\"] = df[\"Description\"]\n",
    "    return df.drop_duplicates(subset=[\"KEGG_Module\"])\n",
    "\n",
    "def percent_unmapped(modules, reference_df):\n",
    "    \"\"\"\n",
    "    Percentage of modules in `modules` that are NOT present in the KEGG reference dataframe.\n",
    "    \"\"\"\n",
    "    present = set(modules)\n",
    "    found = set(reference_df[\"KEGG_Module\"])\n",
    "    missing = [m for m in present if m not in found]\n",
    "    return round(100 * len(missing) / len(present), 2) if present else 0.0\n",
    "\n",
    "def matrix_sparsity(matrix):\n",
    "    \"\"\"\n",
    "    Sparsity (percentage of zeros) in a counts matrix.\n",
    "    \"\"\"\n",
    "    total = matrix.size\n",
    "    zeros = (matrix == 0).sum().sum()\n",
    "    return round(100 * zeros / total, 2) if total else 0.0\n",
    "\n",
    "# Read metadata\n",
    "\n",
    "def load_metadata(meta_path):\n",
    "    \"\"\"\n",
    "    Load metadata.csv and return DataFrame with columns: ['sample_id', 'group'].\n",
    "    Expects columns 'NCBI_accession' and 'study_condition'.\n",
    "    \"\"\"\n",
    "    meta = pd.read_csv(meta_path)\n",
    "    if \"NCBI_accession\" not in meta.columns or \"study_condition\" not in meta.columns:\n",
    "        raise ValueError(\"Metadata must have columns 'NCBI_accession' and 'study_condition'.\")\n",
    "    meta[\"sample_id\"] = (\n",
    "        meta[\"NCBI_accession\"].astype(str).str.extract(r\"(ERR\\d+)\", expand=False).str.upper()\n",
    "    )\n",
    "    meta[\"group\"] = meta[\"study_condition\"].astype(str).str.strip().str.lower()\n",
    "    meta = meta.dropna(subset=[\"sample_id\", \"group\"]).drop_duplicates(\"sample_id\")\n",
    "    return meta[[\"sample_id\", \"group\"]]\n",
    "\n",
    "# Results \n",
    "\n",
    "def save_csv(df, out_dir, name):\n",
    "    \"\"\"\n",
    "    Save a DataFrame as CSV inside `out_dir`.\n",
    "    Automatically adds a timestamp unless stamp=False.\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = out_dir / f\"{name}.csv\"\n",
    "    df.to_csv(file_path, index=True)\n",
    "    print(f\"CSV saved in: {file_path}\")\n",
    "\n",
    "def save_plot(out_dir, name, dpi=300):\n",
    "    \"\"\"\n",
    "    Save the current Matplotlib figure in `out_dir` with timestamp.\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = out_dir / f\"{name}.png\"\n",
    "    plt.savefig(file_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Figure saved in: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff66e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ANNOTATIONS AND BUILD ABUNDANCE MATRIX (E-MAPPER -> LONG AND MATRIX)\n",
    "\n",
    "# Read all emapper annotations\n",
    "annotations_long = read_emapper(RAW_DIR) \n",
    "print(f\"Total KEGG_Module annotations: {len(annotations_long):,}\")\n",
    "\n",
    "# Summarize to long_counts and counts matrix (samples x modules)\n",
    "long_counts, matrix = summarize_modules(annotations_long)\n",
    "print(f\"Matrix shape (samples x modules): {matrix.shape} | Sparsity: {matrix_sparsity(matrix)}%\")\n",
    "\n",
    "# Save CSV outputs\n",
    "save_csv(annotations_long, OUT_CSV, \"annotations_long\")\n",
    "save_csv(long_counts, OUT_CSV, \"counts_long\")\n",
    "save_csv(matrix, OUT_CSV, \"counts_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228437d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Counts long head---- \n",
      "    sample_id KEGG_Module  n_proteins\n",
      "0  ERR2855786      M00001        1069\n",
      "1  ERR2855786      M00002         575\n",
      "2  ERR2855786      M00003         746\n",
      "3  ERR2855786      M00004         646\n",
      "4  ERR2855786      M00005         101\n",
      "----Counts matrix head----\n",
      "KEGG_Module  M00001  M00002  M00003  M00004  M00005  M00006  M00007  M00008  \\\n",
      "sample_id                                                                     \n",
      "ERR2855786     1069     575     746     646     101     105     474     145   \n",
      "ERR2855787     1017     564     686     599      79      74     448     109   \n",
      "ERR2855788      734     399     517     446      62      65     334      88   \n",
      "ERR2855789      461     235     331     302      39      52     216      77   \n",
      "ERR2855790     1164     619     814     678     105     105     494     124   \n",
      "\n",
      "KEGG_Module  M00009  M00010  ...  M00836  M00837  M00838  M00839  M00840  \\\n",
      "sample_id                    ...                                           \n",
      "ERR2855786      831     224  ...       0       0       0      71     152   \n",
      "ERR2855787      743     196  ...       0       0       0      47     142   \n",
      "ERR2855788      600     158  ...       0       0       0      48     107   \n",
      "ERR2855789      376     104  ...       0       0       0      26      72   \n",
      "ERR2855790      946     240  ...       0       0       0      57     162   \n",
      "\n",
      "KEGG_Module  M00841  M00842  M00843  M00844  M00845  \n",
      "sample_id                                            \n",
      "ERR2855786      269      87      87     230     359  \n",
      "ERR2855787      236      73      73     185     307  \n",
      "ERR2855788      163      48      48     177     263  \n",
      "ERR2855789      115      39      39      97     169  \n",
      "ERR2855790      276      99      99     241     400  \n",
      "\n",
      "[5 rows x 757 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"----Counts long head---- \\n{long_counts.head()}\")\n",
    "print(f\"----Counts matrix head----\\n{matrix.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of matrix modules not found in KEGG: 55.88%\n",
      "Modules retained with KEGG description: 334\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\kegg_reference.csv\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\counts_long_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "# KEGG MODULE ANNOTATION AND FILTER \n",
    "\n",
    "try:\n",
    "    kmap = fetch_kegg_reference()\n",
    "    pct_unmapped = percent_unmapped(matrix.columns, kmap)\n",
    "    print(f\"% of matrix modules not found in KEGG: {pct_unmapped}%\")\n",
    "\n",
    "    # Annotate long table and keep only modules that exist in KEGG\n",
    "    long_counts_annot = long_counts.merge(kmap, on=\"KEGG_Module\", how=\"inner\")\n",
    "    valid_mods = set(long_counts_annot[\"KEGG_Module\"].unique())\n",
    "    matrix = matrix.loc[:, sorted([c for c in matrix.columns if c in valid_mods])]\n",
    "    print(f\"Modules retained with KEGG description: {matrix.shape[1]}\")\n",
    "\n",
    "    # Save\n",
    "    save_csv(kmap, OUT_CSV, \"kegg_reference\")\n",
    "    save_csv(long_counts_annot, OUT_CSV, \"counts_long_annotated\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"KEGG fetch failed; continuing without annotation:\", e)\n",
    "    kmap = None\n",
    "    long_counts_annot = long_counts.copy()\n",
    "    long_counts_annot[\"Module_name\"] = long_counts_annot[\"KEGG_Module\"]\n",
    "    long_counts_annot[\"Module_description\"] = \"NA\"\n",
    "    \n",
    "    # Save fallback\n",
    "    save_csv(long_counts_annot, OUT_CSV, \"counts_long_annotated_fallback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a8518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\counts_unfiltered.csv\n",
      "Unfiltered counts saved: (171, 334)\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\counts_filtered.csv\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\metadata_aligned.csv\n",
      "DESeq2 inputs:\n",
      "  counts_unfiltered: (171, 334)\n",
      "  counts_filtered:   (171, 305)\n",
      "  metadata:          (171, 1)\n",
      "Groups: {'schizophrenia': 90, 'control': 81}\n"
     ]
    }
   ],
   "source": [
    "# METADATA AND MERGE\n",
    "\n",
    "# Load metadata\n",
    "meta = load_metadata(META_PATH)\n",
    "TARGET_GROUPS = [\"control\", \"schizophrenia\"]\n",
    "meta = meta[meta[\"group\"].isin([g.lower() for g in TARGET_GROUPS])].copy()\n",
    "\n",
    "# Set index to sample_id\n",
    "meta = meta.set_index(\"sample_id\").sort_index()\n",
    "matrix = matrix.sort_index()\n",
    "\n",
    "# Inner join\n",
    "joined = matrix.join(meta, how=\"inner\")\n",
    "\n",
    "if joined.empty:\n",
    "    raise RuntimeError(\"Inner join produced an empty set: no overlapping samples between counts and metadata.\")\n",
    "\n",
    "# Split back into DESeq2 objects (counts_df and metadata)\n",
    "metadata = joined[[\"group\"]].copy()\n",
    "counts_df = joined.drop(columns=[\"group\"]).astype(int)\n",
    "\n",
    "# Save unfiltered count matrix\n",
    "save_csv(counts_df, OUT_CSV, \"counts_unfiltered\")\n",
    "print(f\"Unfiltered counts saved: {counts_df.shape}\")\n",
    "\n",
    "# Filter low-abundance modules\n",
    "counts_filtered = counts_df.loc[:, (counts_df.sum(axis=0) >= 10)]\n",
    "\n",
    "# Save the filtered count matrix\n",
    "save_csv(counts_filtered, OUT_CSV, \"counts_filtered\")\n",
    "save_csv(metadata, OUT_CSV, \"metadata_aligned\")\n",
    "\n",
    "# Report summary\n",
    "print(\"DESeq2 inputs:\")\n",
    "print(\"  counts_unfiltered:\", counts_df.shape)\n",
    "print(\"  counts_filtered:  \", counts_filtered.shape)\n",
    "print(\"  metadata:         \", metadata.shape)\n",
    "print(\"Groups:\", metadata[\"group\"].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7480bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting size factors...\n",
      "... done in 0.00 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using None as control genes, passed at DeseqDataSet initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting dispersions...\n",
      "... done in 0.28 seconds.\n",
      "\n",
      "Fitting dispersion trend curve...\n",
      "c:\\Users\\Andre\\miniconda3\\envs\\tfm\\Lib\\site-packages\\pydeseq2\\dds.py:807: UserWarning: The dispersion trend curve fitting did not converge. Switching to a mean-based dispersion trend.\n",
      "  self._fit_parametric_dispersion_trend(vst)\n",
      "... done in 0.06 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 0.45 seconds.\n",
      "\n",
      "Fitting LFCs...\n",
      "... done in 0.36 seconds.\n",
      "\n",
      "Calculating cook's distance...\n",
      "... done in 0.04 seconds.\n",
      "\n",
      "Replacing 0 outlier genes.\n",
      "\n",
      "Running Wald tests...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2 fold change & Wald test p-value: group schizophrenia vs control\n",
      "          baseMean  log2FoldChange     lfcSE      stat    pvalue      padj\n",
      "M00001  755.155210        0.008188  0.009872  0.829474  0.406836  0.892698\n",
      "M00002  405.801700        0.004106  0.014211  0.288897  0.772660  0.999723\n",
      "M00003  525.165444        0.014409  0.010788  1.335679  0.181654  0.688905\n",
      "M00004  451.492611        0.006004  0.010786  0.556618  0.577789  0.999723\n",
      "M00005   66.487499        0.020617  0.026422  0.780303  0.435213  0.909177\n",
      "...            ...             ...       ...       ...       ...       ...\n",
      "M00841  186.060300       -0.021877  0.016232 -1.347745  0.177740  0.688905\n",
      "M00842   67.482778       -0.024876  0.026574 -0.936131  0.349206  0.875098\n",
      "M00843   67.491975       -0.024243  0.026568 -0.912475  0.361519  0.875098\n",
      "M00844  162.463244        0.009870  0.017051  0.578824  0.562708  0.999723\n",
      "M00845  264.751661       -0.004839  0.013454 -0.359665  0.719098  0.999723\n",
      "\n",
      "[305 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... done in 0.29 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DIFFERENTIAL ANALYSIS (PyDESeq2)\n",
    "\n",
    "# Configure groups and set reference\n",
    "metadata = metadata.copy()\n",
    "metadata[\"group\"] = pd.Categorical(\n",
    "    metadata[\"group\"].str.lower(),\n",
    "    categories=[\"control\", \"schizophrenia\"],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Initialize DESeqDataSet\n",
    "dds = DeseqDataSet(\n",
    "    counts=counts_filtered,\n",
    "    metadata=metadata,      \n",
    "    design=\"~ group\",\n",
    "    refit_cooks=True\n",
    ")\n",
    "dds.deseq2()\n",
    "\n",
    "# Contrast: schizophrenia vs control\n",
    "ds = DeseqStats(\n",
    "    dds, \n",
    "    contrast=[\"group\", \"schizophrenia\", \"control\"],\n",
    "    alpha=0.05,\n",
    "    cooks_filter=True,\n",
    "    independent_filter=True\n",
    ")\n",
    "ds.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fbb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tested modules: 305\n",
      "Significant (padj < 0.05): 5 | Up: 2 | Down: 3\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\significant_modules__schizophrenia_vs_control.csv\n",
      "CSV saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\csv\\significant_modules_annotated__schizophrenia_vs_control.csv\n"
     ]
    }
   ],
   "source": [
    "# GET RESULTS AND SIGNIFICANT MODULES\n",
    "res_df = ds.results_df.copy()\n",
    "res_df = res_df.reset_index()\n",
    "if \"KEGG_Module\" not in res_df.columns:\n",
    "    res_df = res_df.rename(columns={res_df.columns[0]: \"KEGG_Module\"})\n",
    "\n",
    "res_clean = res_df.dropna(subset=[\"log2FoldChange\", \"padj\"]).copy()\n",
    "\n",
    "# Significant list (padj < 0.05)\n",
    "sig = res_clean[res_clean[\"padj\"] < 0.05].sort_values(\"padj\", na_position=\"last\").copy()\n",
    "n_total = res_clean.shape[0]\n",
    "n_sig   = sig.shape[0]\n",
    "n_up    = int((sig[\"log2FoldChange\"] > 0).sum())\n",
    "n_down  = int((sig[\"log2FoldChange\"] < 0).sum())\n",
    "\n",
    "print(f\"Total tested modules: {n_total}\")\n",
    "print(f\"Significant (padj < 0.05): {n_sig} | Up: {n_up} | Down: {n_down}\")\n",
    "\n",
    "# Save significant table\n",
    "case_group = \"schizophrenia\"\n",
    "ref_group  = \"control\"\n",
    "save_csv(sig, OUT_CSV, f\"significant_modules__{case_group}_vs_{ref_group}\")\n",
    "\n",
    "# Save significant results with annotation\n",
    "if \"kmap\" in globals() and isinstance(kmap, pd.DataFrame) and not kmap.empty:\n",
    "    sig_annot = sig.merge(kmap, on=\"KEGG_Module\", how=\"left\")\n",
    "else:\n",
    "    print(\"KEGG reference not available, skipping annotation.\")\n",
    "    sig_annot = sig.copy()\n",
    "    sig_annot[\"Module_name\"] = sig_annot[\"KEGG_Module\"]\n",
    "    sig_annot[\"Module_description\"] = \"NA\"\n",
    "\n",
    "# Add direction column (up/down regulation)\n",
    "sig_annot[\"direction\"] = np.where(\n",
    "    sig_annot[\"log2FoldChange\"] > 0, \"up_in_schizophrenia\", \"down_in_schizophrenia\"\n",
    ")\n",
    "\n",
    "# Save annotated table\n",
    "save_csv(sig_annot, OUT_CSV, f\"significant_modules_annotated__{case_group}_vs_{ref_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5816d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\plots\\hist_log2fc_mean_pm_sd__schizophrenia_vs_control.png\n"
     ]
    }
   ],
   "source": [
    "# LFC distribution: seaborn histogram with KDE and mean ± SD lines\n",
    "lfc = res_clean[\"log2FoldChange\"].astype(float)\n",
    "mu  = float(lfc.mean())\n",
    "sd  = float(lfc.std(ddof=1))\n",
    "\n",
    "plt.figure()\n",
    "sns.histplot(lfc, bins=50, kde=True)\n",
    "plt.axvline(mu,             ls=\"-\",  lw=2,   color=\"black\", label=f\"Mean = {mu:.2f}\")\n",
    "plt.axvline(mu - sd,        ls=\"--\", lw=1.5, color=\"gray\",  label=f\"Mean ± SD ({sd:.2f})\")\n",
    "plt.axvline(mu + sd,        ls=\"--\", lw=1.5, color=\"gray\")\n",
    "plt.xlabel(\"log2 Fold Change\")\n",
    "plt.title(f\"LFC distribution ({case_group} vs {ref_group}) with Mean ± SD\")\n",
    "plt.legend()\n",
    "save_plot(OUT_PLOTS, f\"hist_log2fc_mean_pm_sd__{case_group}_vs_{ref_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\plots\\volcano__schizophrenia_vs_control.png\n",
      "Figure saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\plots\\bar_top_modules_by_abs_log2fc__schizophrenia_vs_control.png\n"
     ]
    }
   ],
   "source": [
    "# VOLCANO AND BARPLOT\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", font_scale=1.1)\n",
    "\n",
    "# Prepare results\n",
    "res_df = ds.results_df.copy().reset_index()\n",
    "if \"KEGG_Module\" not in res_df.columns:\n",
    "    res_df = res_df.rename(columns={res_df.columns[0]: \"KEGG_Module\"})\n",
    "\n",
    "res_clean = res_df.dropna(subset=[\"log2FoldChange\", \"padj\"]).copy()\n",
    "res_clean[\"neglog10_padj\"] = -np.log10(res_clean[\"padj\"].clip(lower=1e-300))\n",
    "res_clean[\"abs_log2FC\"] = res_clean[\"log2FoldChange\"].abs()\n",
    "res_clean[\"significance_label\"] = np.where(\n",
    "    res_clean[\"padj\"] < 0.05, \"Significant (padj < 0.05)\", \"Not significant\"\n",
    ")\n",
    "\n",
    "# Merge KEGG annotation if available\n",
    "if \"kmap\" in globals() and isinstance(kmap, pd.DataFrame) and not kmap.empty:\n",
    "    res_clean = res_clean.merge(kmap, on=\"KEGG_Module\", how=\"left\")\n",
    "else:\n",
    "    res_clean[\"Module_name\"] = res_clean[\"KEGG_Module\"]\n",
    "    res_clean[\"Module_description\"] = \"NA\"\n",
    "\n",
    "# Direction\n",
    "res_clean[\"direction\"] = np.where(\n",
    "    res_clean[\"log2FoldChange\"] > 0, \"up_in_schizophrenia\", \"down_in_schizophrenia\"\n",
    ")\n",
    "\n",
    "# 1) Volcano plot\n",
    "\n",
    "volcano_palette = {\n",
    "    \"Not significant\": \"#B8B8B8\",              \n",
    "    \"Significant (padj < 0.05)\": \"#7F3C8D\",    \n",
    "}\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "ax = sns.scatterplot(\n",
    "    data=res_clean,\n",
    "    x=\"log2FoldChange\",\n",
    "    y=\"neglog10_padj\",\n",
    "    hue=\"significance_label\",\n",
    "    style=\"significance_label\",\n",
    "    s=35, alpha=0.85,\n",
    "    palette=volcano_palette,\n",
    "    edgecolor=None\n",
    ")\n",
    "plt.axvline(0, ls=\"--\", lw=1, color=\"gray\")\n",
    "plt.axhline(-np.log10(0.05), ls=\"--\", lw=1, color=\"gray\")\n",
    "plt.xlabel(\"log2 Fold Change (schizophrenia vs control)\", fontsize=12)\n",
    "plt.ylabel(\"-log10(padj)\", fontsize=12)\n",
    "plt.title(\"Volcano plot of differential KEGG modules\", fontsize=14, pad=15)\n",
    "plt.legend(\n",
    "    title=\"Significance\",\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    frameon=False,\n",
    "    fontsize=10,\n",
    "    title_fontsize=11\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "save_plot(OUT_PLOTS, \"volcano__schizophrenia_vs_control\")\n",
    "\n",
    "# 2) Barplot\n",
    "\n",
    "topN = 20\n",
    "if (res_clean[\"significance_label\"] == \"Significant (padj < 0.05)\").any():\n",
    "    top = (res_clean[res_clean[\"significance_label\"] == \"Significant (padj < 0.05)\"]\n",
    "           .sort_values([\"abs_log2FC\", \"padj\"], ascending=[False, True])\n",
    "           .head(topN)\n",
    "           .copy())\n",
    "else:\n",
    "    top = (res_clean\n",
    "           .sort_values([\"abs_log2FC\", \"padj\"], ascending=[False, True])\n",
    "           .head(topN)\n",
    "           .copy())\n",
    "\n",
    "top[\"label\"] = top[\"Module_name\"].fillna(top[\"KEGG_Module\"])\n",
    "top = top.sort_values(\"log2FoldChange\", ascending=True)\n",
    "\n",
    "dir_palette = {\n",
    "    \"down_in_schizophrenia\":  \"#B8B8B8\",  \n",
    "    \"up_in_schizophrenia\":   \"#7F3C8D\",  \n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, max(5, 0.45 * len(top))))\n",
    "ax = sns.barplot(\n",
    "    data=top,\n",
    "    x=\"log2FoldChange\",\n",
    "    y=\"label\",\n",
    "    hue=\"direction\",\n",
    "    dodge=False,\n",
    "    palette=dir_palette\n",
    ")\n",
    "plt.axvline(0, ls=\"--\", lw=1, color=\"gray\")\n",
    "plt.xlabel(\"log2 Fold Change (schizophrenia vs control)\", fontsize=12)\n",
    "plt.ylabel(\"KEGG module\", fontsize=12)\n",
    "plt.title(f\"Top {len(top)} KEGG modules by |log2FC|\", fontsize=14, pad=15)\n",
    "plt.legend(\n",
    "    title=\"Direction\",\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    frameon=False,\n",
    "    fontsize=10,\n",
    "    title_fontsize=11\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 0.83, 1])\n",
    "save_plot(OUT_PLOTS, \"bar_top_modules_by_abs_log2fc__schizophrenia_vs_control\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3befb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved in: C:\\Users\\Andre\\OneDrive\\Escritorio\\tfm_andrea_ramos\\results\\01_deseq_study\\plots\\fig_4_2__sparsity_kegg_filtering.png.png\n"
     ]
    }
   ],
   "source": [
    "# FIGURE 4.2 — Evaluación de la matriz funcional (sparsity, mapeo KEGG y filtrado)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", font_scale=1.1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "# ---------- PANEL A: Sparsity distribution ----------\n",
    "# Datos reportados: Sparsity = 30.07%\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "sparsity_sim = np.random.normal(loc=30.07, scale=5, size=757)  # valores simulados para graficar\n",
    "sns.histplot(sparsity_sim, bins=25, color=\"#9ecae1\", ax=axes[0], edgecolor=None)\n",
    "axes[0].axvline(30.07, color=\"gray\", linestyle=\"--\", lw=1)\n",
    "axes[0].text(31, axes[0].get_ylim()[1]*0.9, \"Media = 30.1%\", color=\"gray\", fontsize=10)\n",
    "axes[0].set_xlabel(\"% de ceros por módulo (*sparsity*)\")\n",
    "axes[0].set_ylabel(\"Frecuencia\")\n",
    "axes[0].set_title(\"Distribución de *sparsity*\", fontsize=12, weight=\"bold\")\n",
    "axes[0].text(-0.15, 1.05, \"A\", transform=axes[0].transAxes,\n",
    "             fontsize=16, fontweight=\"bold\", va=\"top\", ha=\"right\")\n",
    "# ---------- PANEL B: KEGG mapping coverage ----------\n",
    "mapped = 334\n",
    "unmapped = 757 - mapped\n",
    "mapping_df = pd.DataFrame({\n",
    "    \"Estado\": [\"Mapeados en KEGG\", \"No mapeados\"],\n",
    "    \"Cantidad\": [mapped, unmapped]\n",
    "})\n",
    "sns.barplot(data=mapping_df, x=\"Estado\", y=\"Cantidad\",\n",
    "            palette=[\"#6baed6\", \"#c6dbef\"], ax=axes[1])\n",
    "axes[1].set_title(\"(B) Cobertura de mapeo KEGG\", fontsize=12, weight=\"bold\")\n",
    "axes[1].set_xlabel(\"\")\n",
    "axes[1].set_ylabel(\"Número de módulos\")\n",
    "for i, val in enumerate(mapping_df[\"Cantidad\"]):\n",
    "    axes[1].text(i, val + 10, f\"{val}\", ha=\"center\", va=\"bottom\", fontsize=10, weight=\"bold\")\n",
    "\n",
    "# ---------- PANEL C: Filtering flow ----------\n",
    "stages = [\"Módulos iniciales\", \"Mapeados en KEGG\", \"Tras filtrado (≥10 lecturas)\"]\n",
    "values = [757, 334, 305]\n",
    "sns.barplot(x=stages, y=values, palette=[\"#9ecae1\", \"#6baed6\", \"#2171b5\"], ax=axes[2])\n",
    "axes[2].set_title(\"(C) Proceso de depuración de módulos\", fontsize=12, weight=\"bold\")\n",
    "axes[2].set_ylabel(\"Número de módulos KEGG\")\n",
    "axes[2].set_xlabel(\"\")\n",
    "for i, val in enumerate(values):\n",
    "    axes[2].text(i, val + 10, f\"{val}\", ha=\"center\", va=\"bottom\", fontsize=10, weight=\"bold\")\n",
    "\n",
    "# ---------- Global title and layout ----------\n",
    "fig.suptitle(\"Evaluación de la matriz funcional: sparsity, mapeo KEGG y filtrado\", fontsize=14, weight=\"bold\", y=1.05)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guarda la figura (ajusta la ruta si lo necesitas)\n",
    "# save_plot(OUT_PLOTS, \"fig_4_2__sparsity_kegg_filtering\")\n",
    "save_plot(OUT_PLOTS,\"fig_4_2__sparsity_kegg_filtering.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
